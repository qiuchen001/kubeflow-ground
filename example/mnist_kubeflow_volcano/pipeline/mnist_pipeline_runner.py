import os
from kfp import dsl
try:
    from kfp import kubernetes
    _HAS_KFP_K8S = True
except Exception:
    _HAS_KFP_K8S = False

from kfp.compiler import Compiler
from kfp.client import Client
from kfp.components import load_component_from_file

# --- è¾…åŠ©å‡½æ•°ï¼šåŠ è½½ç»„ä»¶ YAML ---
def get_component_op(yaml_file):
    # å‡è®¾ YAML æ–‡ä»¶åœ¨ä¸æ­¤è„šæœ¬åŒçº§çš„ç›®å½•
    return load_component_from_file(os.path.join(os.path.dirname(__file__), "..", yaml_file))

# åŠ è½½ç»„ä»¶ (ç¡®ä¿ç»„ä»¶ YAML å·²ç»ç”Ÿæˆ)
try:
    preprocess_op = get_component_op('mnist_preprocess_component.yaml')
    train_op = get_component_op('mnist_train_component.yaml')
except FileNotFoundError:
    print("é”™è¯¯: æ‰¾ä¸åˆ°ç»„ä»¶ YAML æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œç»„ä»¶ç”Ÿæˆæ­¥éª¤ã€‚")
    exit(1)


# --- Pipeline å®šä¹‰ï¼šDAG ç»“æ„å’Œ Volcano æ³¨å…¥ ---
@dsl.pipeline(
    name='mnist-volcano-training',
    # ğŸŒŸ æ›¿æ¢ä¸ºä½ çš„å®é™… Artifact Store (e.g., gs://my-bucket/runs æˆ– s3://my-bucket/runs)
    pipeline_root='minio://minio-service.kubeflow.svc:9000/mlpipeline/mnist-runs' 
)
def mnist_pipeline(
    epochs: int = 10, 
    lr: float = 0.001
):
    # 1. å¯¼å…¥åŸå§‹æ•°æ®ä¸º Dataset Artifactï¼ˆå¯æ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„ï¼‰
    raw_data_importer = dsl.importer(
        # artifact_uri='s3://kubeflow-pipeline/raw/train_data.csv',
        # artifact_uri='minio://minio-service.kubeflow.svc:9000/mlpipeline/raw/train_data.csv',
        # artifact_uri='s3://minio-service.kubeflow.svc:9000/mlpipeline/raw/train_data.csv',
        artifact_uri='s3://mlpipeline/raw/train_data.csv',
        artifact_class=dsl.Dataset
    )
    # 2. æ•°æ®é¢„å¤„ç†ä»»åŠ¡
    prep_task = preprocess_op(raw_data=raw_data_importer.outputs['artifact'])
    
    # 3. æ¨¡å‹è®­ç»ƒä»»åŠ¡ (é…ç½® Volcano è°ƒåº¦)
    train_task = train_op(
        # ä¸²è¡Œä¾èµ–ï¼šæ•°æ®ä¼ é€’ (KFP è‡ªåŠ¨å¤„ç†è·¯å¾„æ˜ å°„)
        training_data=prep_task.outputs['processed_data'], 
        epochs=epochs,
        lr=lr
    )
    
    # --- ğŸŒŸ å…³é”®ï¼šVolcano è°ƒåº¦æ³¨å…¥ç‚¹ ---
    # è¿™å°†ç¡®ä¿è¿™ä¸ªè®­ç»ƒä»»åŠ¡çš„ Pod ç”± Volcano è°ƒåº¦å™¨å¤„ç†
    if _HAS_KFP_K8S:
        # æ³¨å…¥ MinIO å‡­è¯
        kubernetes.use_secret_as_env(
            task=prep_task,
            secret_name='mlpipeline-minio-artifact',
            secret_key_to_env={
                'accesskey': 'AWS_ACCESS_KEY_ID',
                'secretkey': 'AWS_SECRET_ACCESS_KEY'
            }
        )
        # æ³¨å…¥ Region (S3 Client éœ€è¦)
        prep_task.set_env_variable('AWS_REGION', 'us-east-1')
        # æ³¨å…¥ Endpoint (æŒ‡å‘é›†ç¾¤å†… MinIO)
        prep_task.set_env_variable('AWS_ENDPOINT_URL', 'http://minio-service.kubeflow.svc:9000')
        # å¼ºåˆ¶ Path Style (è§£å†³ DNS è§£æé—®é¢˜)
        prep_task.set_env_variable('S3_FORCE_PATH_STYLE', 'true')
        prep_task.set_env_variable('AWS_S3_FORCE_PATH_STYLE', 'true')
        prep_task.set_env_variable('AWS_USE_PATH_STYLE_REQUESTS', 'true')
        prep_task.set_env_variable('AWS_S3_USE_PATH_STYLE', 'true')

        kubernetes.use_secret_as_env(
            task=train_task,
            secret_name='mlpipeline-minio-artifact',
            secret_key_to_env={
                'accesskey': 'AWS_ACCESS_KEY_ID',
                'secretkey': 'AWS_SECRET_ACCESS_KEY'
            }
        )
        # æ³¨å…¥ Region (S3 Client éœ€è¦)
        train_task.set_env_variable('AWS_REGION', 'us-east-1')
        # æ³¨å…¥ Endpoint (æŒ‡å‘é›†ç¾¤å†… MinIO)
        train_task.set_env_variable('AWS_ENDPOINT_URL', 'http://minio-service.kubeflow.svc:9000')
        # å¼ºåˆ¶ Path Style (è§£å†³ DNS è§£æé—®é¢˜)
        train_task.set_env_variable('S3_FORCE_PATH_STYLE', 'true')
        train_task.set_env_variable('AWS_S3_FORCE_PATH_STYLE', 'true')
        train_task.set_env_variable('AWS_USE_PATH_STYLE_REQUESTS', 'true')
        train_task.set_env_variable('AWS_S3_USE_PATH_STYLE', 'true')

        kubernetes.add_pod_annotation(
            task=train_task,
            annotation_key='scheduling.k8s.io/group-name', 
            annotation_value='mnist-gpu-group'
        )
        kubernetes.add_pod_annotation(
            task=train_task,
            annotation_key='scheduling.volcano.sh/schedulerName', 
            annotation_value='volcano' 
        )
    # è¯·æ±‚ GPU èµ„æºï¼ŒVolcano å°†åŸºäºæ­¤è¿›è¡Œæ‰¹é‡è°ƒåº¦
    train_task.set_cpu_limit('4').set_memory_limit('16G').set_gpu_limit(1)


# --- ç¼–è¯‘å’Œè¿è¡Œé€»è¾‘ ---

# ç¼–è¯‘æˆå¯æ‰§è¡Œ JSON
Compiler().compile(
    pipeline_func=mnist_pipeline,
    package_path='mnist_pipeline.yaml'
)
print("Pipeline ç¼–è¯‘æˆåŠŸï¼šmnist_pipeline.yaml")

# æäº¤åˆ° KFP API Server è¿è¡Œ
try:
    # ğŸŒŸ æ›¿æ¢ä¸ºä½ çš„ KFP API Endpoint æˆ–ç›´æ¥ä½¿ç”¨ Kubeconfig
    # æç¤º: å¦‚æœåœ¨ K8s é›†ç¾¤å†…éƒ¨è¿è¡Œï¼Œä¸»æœºåé€šå¸¸æ˜¯ 'http://ml-pipeline.kubeflow.svc.cluster.local:8888'
    KFP_API_HOST = os.environ.get("KFP_HOST", "http://localhost:30088") 
    
    client = Client(host=KFP_API_HOST)
    
    run = client.create_run_from_pipeline_func(
        mnist_pipeline,
        arguments={'epochs': 15, 'lr': 0.0001},
        experiment_name='MNIST Volcano Training Run'
    )
    print(f"\n--- å·¥ä½œæµè¿è¡ŒæˆåŠŸï¼ ---")
    print(f"Run ID: {run.run_id}")
    print(f"è¯·åœ¨ KFP UI ä¸­æŸ¥çœ‹è¿è¡ŒçŠ¶æ€ã€‚")

except Exception as e:
    print(f"\n--- é”™è¯¯ï¼šæ— æ³•è¿æ¥æˆ–æäº¤å·¥ä½œæµåˆ° KFP API Server ---")
    print(f"è¯·æ£€æŸ¥ KFP_API_HOST ({KFP_API_HOST}) æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠ KFP åç«¯æ˜¯å¦åœ¨è¿è¡Œã€‚")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
